{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mahotas\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://github.com/credo-science/CREDO-ML/blob/main/offline_trigger/Wavelet_BINARY_ALFA.ipynb\n",
    "def loadData(path, verbose=True):\n",
    "\n",
    "  import cv2\n",
    "  import glob\n",
    "\n",
    "  dots = []\n",
    "  lines = []\n",
    "  worms = []\n",
    "  artefacts = []\n",
    "\n",
    "  for img in glob.glob(path+\"hits_votes_4_Dots/*.png\"):\n",
    "      n = cv2.imread(img)\n",
    "      dots.append(n)\n",
    "  target_dots = [0 for _ in dots]\n",
    "\n",
    "  for img in glob.glob(path+\"hits_votes_4_Lines/*.png\"):\n",
    "      n = cv2.imread(img)\n",
    "      lines.append(n)\n",
    "  target_lines = [1 for _ in lines]\n",
    "\n",
    "  for img in glob.glob(path+\"hits_votes_4_Worms/*.png\"):\n",
    "      n = cv2.imread(img)\n",
    "      worms.append(n)\n",
    "  target_worms = [2 for _ in worms]\n",
    "\n",
    "#   for img in glob.glob(path+\"artefacts/*.png\"):\n",
    "#       n = cv2.imread(img)\n",
    "#       artefacts.append(n)\n",
    "#   target_artefacts = [3 for _ in artefacts]\n",
    "\n",
    "  images=dots+lines+worms#+artefacts\n",
    "\n",
    "  #target_signals_binary = [0 for _ in (dots+lines+worms)]\n",
    "  #target_artefacts_binary = [1 for _ in artefacts]\n",
    "\n",
    "  #targets=target_signals_binary+target_artefacts_binary\n",
    "  targets=target_dots+target_lines+target_worms#+target_artefacts\n",
    "\n",
    "  if verbose:\n",
    "    print(len(images),len(targets))\n",
    "    print(images[0].shape)\n",
    "    print(len(dots), len(lines), len(worms), len(artefacts))\n",
    "\n",
    "\n",
    "  return (images, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_reduction(X: np.ndarray):\n",
    "    \"\"\" Function for Principal Component Analysis (PCA)\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Input data.\n",
    "\n",
    "    Returns:\n",
    "        ret (np.ndarray): Data after PCA.\n",
    "        ratio (np.float64): sum of explained_variance_ratio_\n",
    "    \"\"\"\n",
    "    X_norm = preprocessing.normalize(X)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X_norm)\n",
    "\n",
    "    ret=pca.transform(X_norm)\n",
    "\n",
    "    ratio = pca.explained_variance_ratio_.sum()\n",
    "\n",
    "    return ret, ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(X: list, dim: int, blur_ksize: tuple, thresh_min: int, thresh_max: int, zernike_radius: int, zernike_degree: int) -> np.ndarray:\n",
    "    \"\"\"Preprocess data.\n",
    "\n",
    "    Args:\n",
    "        X (list): Input data.\n",
    "        dim (int): PCA dimensionality.\n",
    "        blur_ksize (tuple): Blur kernel size.\n",
    "        thresh_min (int): Threshold minimal value.\n",
    "        thresh_max (int): Threshold maximal value.\n",
    "        zernike_radius (int): Zernike moments radius.\n",
    "        zernike_degree (int): Zernike moments degree.\n",
    "\n",
    "    Returns:\n",
    "        ret (np.ndarray): Preprocessed data.\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO: remove below code after pca is implemented\n",
    "    # get number of zernike moments for given degree\n",
    "    dim = mahotas.features.zernike_moments(\n",
    "        cv2.cvtColor(X[0], cv2.COLOR_RGB2GRAY), zernike_radius, zernike_degree\n",
    "        ).shape[0]\n",
    "    \n",
    "    ret: np.ndarray = np.zeros((len(X), dim))\n",
    "    for i in range(len(X)):\n",
    "\n",
    "        # Preprocess image before extracting zernike moments\n",
    "        img: np.ndarray = cv2.cvtColor(X[i], cv2.COLOR_RGB2GRAY)\n",
    "        img = cv2.GaussianBlur(img, blur_ksize, 0)\n",
    "        _, img = cv2.threshold(img, thresh_min, thresh_max, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Extract zernike moments\n",
    "        zernike: np.ndarray = mahotas.features.zernike_moments(img, zernike_radius, zernike_degree)\n",
    "        \n",
    "        ret[i,:] = zernike\n",
    "    \n",
    "    ret, _ = pca_reduction(ret)\n",
    "        \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=\"../data/hit-images-final/\"\n",
    "\n",
    "X, y = loadData(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 0\n",
    "blur_ksize = (5, 5)\n",
    "thresh_min = 0\n",
    "thresh_max = 255 \n",
    "zernike_radius = 30 \n",
    "zernike_degree = 8\n",
    "\n",
    "X_= preprocess_data(X, dim, blur_ksize, thresh_min, thresh_max, zernike_radius, zernike_degree)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
